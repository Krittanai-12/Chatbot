import os
from dotenv import load_dotenv
import google.generativeai as genai
import pandas as pd
import streamlit as st
from prompt import PROMPT_WORKAW
from google.generativeai.types import HarmCategory, HarmBlockThreshold
from document_reader import get_kmutnb_summary


# ‡πÇ‡∏´‡∏•‡∏î‡∏Ñ‡πà‡∏≤ environment ‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå .env ‡πÅ‡∏•‡πâ‡∏ß‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ API key
load_dotenv()
api_key = os.getenv("GENAI_API_KEY")
if not api_key:
    raise RuntimeError("GENAI_API_KEY not set. Add it to .env or your environment variables.")

genai.configure(api_key=api_key)

# ----------------- CONFIG -----------------
generation_config = {
    "temperature": 0.0,
    "top_p": 0.90,
    "top_k": 40,
    "max_output_tokens": 2048,
    "response_mime_type": "text/plain",
    "candidate_count": 1,
}

SAFETY_SETTINGS = {
    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,
    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,
    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,
    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE
}

# ----------------- SYNONYMS -----------------
SYNONYMS = {
    "‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢": ["mean", "average", "‡∏Ñ‡πà‡∏≤‡∏Å‡∏•‡∏≤‡∏á", "‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡πÄ‡∏•‡∏Ç‡∏Ñ‡∏ì‡∏¥‡∏ï"],
    "‡∏°‡∏±‡∏ò‡∏¢‡∏ê‡∏≤‡∏ô": ["median", "‡∏Ñ‡πà‡∏≤‡∏Å‡∏•‡∏≤‡∏á"],
    "‡∏ê‡∏≤‡∏ô‡∏ô‡∏¥‡∏¢‡∏°": ["mode", "‡πÇ‡∏´‡∏°‡∏î"],
    "‡∏™‡πà‡∏ß‡∏ô‡πÄ‡∏ö‡∏µ‡πà‡∏¢‡∏á‡πÄ‡∏ö‡∏ô‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô": ["standard deviation", "SD", "‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏õ‡∏£‡∏õ‡∏£‡∏ß‡∏ô"],
    "‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏õ‡∏£‡∏õ‡∏£‡∏ß‡∏ô": ["variance", "var"],
    "‡∏û‡∏¥‡∏™‡∏±‡∏¢": ["range", "‡∏Ñ‡πà‡∏≤‡∏û‡∏¥‡∏™‡∏±‡∏¢"],
    "‡∏Ñ‡∏ß‡∏≠‡πÑ‡∏ó‡∏•‡πå": ["quartile", "Q1", "Q2", "Q3"],
    "‡πÄ‡∏õ‡∏≠‡∏£‡πå‡πÄ‡∏ã‡πá‡∏ô‡πÑ‡∏ó‡∏•‡πå": ["percentile"],
    "‡∏Å‡∏≤‡∏£‡πÅ‡∏à‡∏Å‡πÅ‡∏à‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏µ‡πà": ["frequency distribution", "‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡πÅ‡∏à‡∏Å‡πÅ‡∏à‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏µ‡πà"],
    "‡∏Æ‡∏¥‡∏™‡πÇ‡∏ï‡πÅ‡∏Å‡∏£‡∏°": ["histogram", "‡∏Å‡∏£‡∏≤‡∏ü‡πÅ‡∏ó‡πà‡∏á"],
    "‡∏Å‡∏£‡∏≤‡∏ü": ["chart", "graph", "‡πÅ‡∏ú‡∏ô‡∏†‡∏π‡∏°‡∏¥"],
    "‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô": ["probability", "‡πÇ‡∏≠‡∏Å‡∏≤‡∏™"],
    "‡∏Å‡∏≤‡∏£‡∏™‡∏∏‡πà‡∏°‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á": ["sampling", "‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á"],
    "‡∏õ‡∏£‡∏∞‡∏ä‡∏≤‡∏Å‡∏£": ["population"],
    "‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏™‡∏°‡∏°‡∏ï‡∏¥‡∏ê‡∏≤‡∏ô": ["hypothesis testing", "‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö"],
    "‡∏Ñ‡πà‡∏≤ Z": ["Z-score", "‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô"],
    "‡∏Ñ‡πà‡∏≤ T": ["T-score", "t-test"],
    "‡∏™‡∏´‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå": ["correlation", "‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå"],
    "‡∏Å‡∏≤‡∏£‡∏ñ‡∏î‡∏ñ‡∏≠‡∏¢": ["regression", "‡πÄ‡∏™‡πâ‡∏ô‡∏ñ‡∏î‡∏ñ‡∏≠‡∏¢"],
    "‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏ä‡∏¥‡∏á‡∏õ‡∏£‡∏¥‡∏°‡∏≤‡∏ì": ["quantitative data", "‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç"],
    "‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏ä‡∏¥‡∏á‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û": ["qualitative data", "‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏ä‡∏¥‡∏á‡∏Å‡∏•‡∏∏‡πà‡∏°"],
    "‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡∏ï‡πà‡∏≠‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á": ["continuous variable"],
    "‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡πÑ‡∏°‡πà‡∏ï‡πà‡∏≠‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á": ["discrete variable"],
}

def expand_synonyms(text: str) -> list:
    """‡∏Ç‡∏¢‡∏≤‡∏¢‡∏Ñ‡∏≥‡∏Ñ‡πâ‡∏ô‡∏à‡∏≤‡∏Å SYNONYMS"""
    expanded = set()
    lower = text.lower()
    for key, alts in SYNONYMS.items():
        if key.lower() in lower:
            for a in alts:
                expanded.add(a)
        for a in alts:
            if a.lower() in lower:
                expanded.add(key)
                expanded.update([x for x in alts if x != a])
    return sorted(expanded)

# ----------------- MODEL (Gemini 2.5) -----------------
@st.cache_resource(show_spinner=False)
def get_model():
    return genai.GenerativeModel(
        model_name="gemini-2.5-flash",  
        safety_settings=SAFETY_SETTINGS,
        generation_config=generation_config,
        system_instruction=PROMPT_WORKAW
    )

model = get_model()

# ----------------- PDF READER (‡∏≠‡πà‡∏≤‡∏ô‡∏ó‡∏∏‡∏Å‡∏´‡∏ô‡πâ‡∏≤) -----------------
def read_full_pdf(pdf_path: str) -> str:
    """‡∏≠‡πà‡∏≤‡∏ô PDF ‡∏ó‡∏∏‡∏Å‡∏´‡∏ô‡πâ‡∏≤‡∏î‡πâ‡∏ß‡∏¢ PyPDF2"""
    try:
        import PyPDF2
        text = ""
        with open(pdf_path, 'rb') as file:
            pdf_reader = PyPDF2.PdfReader(file)
            total_pages = len(pdf_reader.pages)
            
            for page_num in range(total_pages):
                page = pdf_reader.pages[page_num]
                text += page.extract_text() + "\n\n"
        
        return text.strip()
    except ImportError:
        st.error("‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á PyPDF2: pip install PyPDF2")
        return ""
    except Exception as e:
        st.error(f"Error reading PDF: {e}")
        return ""

# ----------------- FILE PATH MANAGEMENT -----------------
def find_dataset_file():
    """‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå dataset ‡∏à‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢‡∏ó‡∏µ‡πà"""
    possible_paths = [
        "DataSetMath.pdf",
        "./DataSetMath.pdf",
        os.path.join(os.path.dirname(__file__), "DataSetMath.pdf"),
        os.path.join(os.getcwd(), "DataSetMath.pdf"),
        "/app/DataSetMath.pdf",
        "/mount/src/DataSetMath.pdf",
        os.path.join("data", "DataSetMath.pdf"),
        os.path.join("assets", "DataSetMath.pdf"),
        os.path.join("documents", "DataSetMath.pdf"),
        "dataset_Math.pdf",
        "DataSetMath.pdf",
    ]

    for path in possible_paths:
        if os.path.exists(path):
            return path
    return None

def get_dataset_path():
    """‡∏´‡∏≤ path ‡∏Ç‡∏≠‡∏á‡πÑ‡∏ü‡∏•‡πå dataset ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÅ‡∏™‡∏î‡∏á debug info"""
    found_path = find_dataset_file()
    if found_path:
        return found_path

    st.sidebar.write("üîç **Debug Info:**")
    st.sidebar.write(f"Current working directory: `{os.getcwd()}`")
    try:
        script_dir = os.path.dirname(__file__)
    except NameError:
        script_dir = "(no __file__ in this env)"
    st.sidebar.write(f"Script directory: `{script_dir}`")

    try:
        files = os.listdir(os.getcwd())
        pdf_files = [f for f in files if f.lower().endswith('.pdf')]
        st.sidebar.write(f"PDF files found: {pdf_files}")
        st.sidebar.write(f"All files in current dir: {files[:10]}...")
    except Exception as e:
        st.sidebar.write(f"Error listing files: {e}")

    return None

# ----------------- IO & CACHE -----------------
@st.cache_data(show_spinner=True)
def load_kmutnb_summary(path: str) -> str:
    """Load ‡πÅ‡∏•‡∏∞ cache ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å PDF (‡∏≠‡πà‡∏≤‡∏ô‡∏ó‡∏∏‡∏Å‡∏´‡∏ô‡πâ‡∏≤)"""
    try:
        # ‡∏•‡∏≠‡∏á‡πÉ‡∏ä‡πâ read_full_pdf ‡∏Å‡πà‡∏≠‡∏ô
        content = read_full_pdf(path)
        if content:
            return content
        # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ ‡πÉ‡∏ä‡πâ document_reader ‡πÄ‡∏î‡∏¥‡∏°
        return get_kmutnb_summary(path)
    except Exception as e:
        return f"Error loading PDF: {str(e)}"

# ----------------- UPLOAD FALLBACK -----------------
def handle_file_upload():
    """‡πÉ‡∏´‡πâ user ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏≠‡∏á‡∏ñ‡πâ‡∏≤‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠"""
    st.warning("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå DataSetMath.pdf ‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö")
    st.info("üí° ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå dataset ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì")

    uploaded_file = st.file_uploader(
        "‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå PDF Dataset",
        type=['pdf'],
        help="‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå DataSetMath.pdf ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏ü‡∏•‡πå PDF ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏≤‡∏¢‡∏ß‡∏¥‡∏ä‡∏≤‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥ KMUTNB"
    )

    if uploaded_file is not None:
        temp_path = f"temp_{uploaded_file.name}"
        with open(temp_path, "wb") as f:
            f.write(uploaded_file.getbuffer())

        st.success(f"‚úÖ ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå {uploaded_file.name} ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß")
        return temp_path

    return None

# ----------------- UI -----------------
def clear_history():
    st.session_state["messages"] = [
        {"role": "model", "content": "‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ! ‡∏°‡∏µ‡∏≠‡∏∞‡πÑ‡∏£‡πÉ‡∏´‡πâ‡∏ä‡πà‡∏ß‡∏¢‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏£‡∏≤‡∏¢‡∏ß‡∏¥‡∏ä‡∏≤‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥ KMUTNB"}
    ]
    st.session_state.pop("chat_session", None)
    st.rerun()

with st.sidebar:
    if st.button("Clear History"):
        clear_history()

    st.markdown("---")
    st.subheader("üìÅ File Status")

st.title("üí¨ ‡∏ß‡∏¥‡∏ä‡∏≤‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥ Chatbot")

if "messages" not in st.session_state:
    st.session_state["messages"] = [
        {
            "role": "model",
            "content": "‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ! ‡∏°‡∏µ‡∏≠‡∏∞‡πÑ‡∏£‡πÉ‡∏´‡πâ‡∏ä‡πà‡∏ß‡∏¢‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏£‡∏≤‡∏¢‡∏ß‡∏¥‡∏ä‡∏≤‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥ KMUTNB",
        }
    ]

# ----------------- LOAD DATASET -----------------
file_path = get_dataset_path()

if file_path is None:
    file_path = handle_file_upload()

if file_path is None:
    st.error("‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå dataset ‡πÑ‡∏î‡πâ ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡∏´‡∏£‡∏∑‡∏≠‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á")
    st.stop()

with st.sidebar:
    st.success(f"‚úÖ Using file: `{os.path.basename(file_path)}`")
    st.caption(f"Full path: `{file_path}`")

try:
    file_content = load_kmutnb_summary(file_path)
    if isinstance(file_content, str) and file_content.startswith("Error"):
        st.error(file_content)
        st.info("üí° ‡∏•‡∏≠‡∏á‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÑ‡∏ü‡∏•‡πå PDF ‡∏´‡∏£‡∏∑‡∏≠‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏´‡∏°‡πà")
        st.stop()
    else:
        with st.sidebar:
            st.info(f"üìÑ Content loaded: {len(file_content)} characters")
except Exception as e:
    st.error(f"Error reading file: {e}")
    st.stop()

# ----------------- CREATE / REUSE CHAT SESSION -----------------
def ensure_chat_session():
    if "chat_session" not in st.session_state:
        base_history = [
            {
                "role": "model",
                "parts": [{"text": "‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏´‡πâ‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ó‡∏µ‡πà‡πÅ‡∏ô‡∏ö‡πÑ‡∏ß‡πâ"}],
            },
            {
                "role": "user",
                "parts": [{
                    "text": (
                        "‡∏ô‡∏µ‡πà‡∏Ñ‡∏∑‡∏≠‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‡∏£‡∏≤‡∏¢‡∏ß‡∏¥‡∏ä‡∏≤‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥ ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î:\n\n"
                        + file_content
                    )
                }],
            },
        ]
        st.session_state["chat_session"] = model.start_chat(history=base_history)

ensure_chat_session()

# ----------------- RENDER HISTORY -----------------
def render_messages(limit_last:int = 20):
    for msg in st.session_state["messages"][-limit_last:]:
        st.chat_message(msg["role"]).write(msg["content"])

render_messages()

# ----------------- HANDLE INPUT -----------------
prompt = st.chat_input(placeholder="‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö ‡∏£‡∏≤‡∏¢‡∏ß‡∏¥‡∏ä‡∏≤‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥ ‚ú®")

def trim_history(max_pairs:int = 8):
    """‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß history ‡πÉ‡∏ô UI"""
    msgs = st.session_state["messages"]
    if len(msgs) > (2 * max_pairs + 1):
        st.session_state["messages"] = msgs[-(2 * max_pairs + 1):]

def generate_response(user_text: str):
    st.session_state["messages"].append({"role": "user", "content": user_text})
    st.chat_message("user").write(user_text)

    # ‡πÇ‡∏´‡∏°‡∏î‡∏™‡∏±‡πâ‡∏ô ‡πÜ ‡∏Ç‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì
    if user_text.lower().startswith("add") or user_text.lower().endswith("add"):
        reply = "‡∏Ç‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥"
        st.session_state["messages"].append({"role": "model", "content": reply})
        st.chat_message("model").write(reply)
        trim_history()
        return

    # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° prompt ‡πÅ‡∏ö‡∏ö‡πÑ‡∏°‡πà‡πÄ‡∏™‡∏£‡∏¥‡∏°‡∏Ñ‡∏≥
    syns = expand_synonyms(user_text)
    syn_hint = f" (‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á: {', '.join(syns)})" if syns else ""
    
    final_prompt = f"""{user_text}{syn_hint}

‡∏Å‡∏é‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö:
- ‡∏ï‡∏≠‡∏ö‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÉ‡∏ô Dataset
- ‡∏´‡πâ‡∏≤‡∏°‡πÅ‡∏ï‡πà‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö ‡∏´‡πâ‡∏≤‡∏°‡∏Ñ‡∏≤‡∏î‡πÄ‡∏î‡∏≤
- ‡∏ï‡∏≠‡∏ö‡∏™‡∏±‡πâ‡∏ô ‡∏Å‡∏£‡∏∞‡∏ä‡∏±‡∏ö ‡∏ï‡∏£‡∏á‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô
- ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ‡∏Ñ‡∏≥‡∏ß‡πà‡∏≤ "‡∏Ñ‡∏£‡∏±‡∏ö" ‡∏´‡∏£‡∏∑‡∏≠ "‡∏Ñ‡πà‡∏∞"
- ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‡πÉ‡∏´‡πâ‡∏ï‡∏≠‡∏ö‡∏ß‡πà‡∏≤ "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ô‡∏µ‡πâ‡πÉ‡∏ô Dataset ‡∏Ç‡∏≠‡∏á‡∏£‡∏≤‡∏¢‡∏ß‡∏¥‡∏ä‡∏≤‡∏ô‡∏µ‡πâ ‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢" """

    placeholder = st.chat_message("model")
    stream_box = placeholder.empty()
    collected = []

    try:
        for chunk in st.session_state["chat_session"].send_message(final_prompt, stream=True):
            piece = getattr(chunk, "text", None)
            if piece:
                collected.append(piece)
                stream_box.write("".join(collected))
        final_text = "".join(collected).strip() or "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"
            
    except Exception as e:
        final_text = f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {e}"

    st.session_state["messages"].append({"role": "model", "content": final_text})
    trim_history()

if prompt:
    generate_response(prompt)